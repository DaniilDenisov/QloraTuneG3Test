transformers>=4.40.0
peft>=0.7.0
bitsandbytes>=0.41.0
datasets>=2.14.0
accelerate>=0.25.0
huggingface-hub>=0.19.0

# Optional: Only needed for serving with vLLM (see serve_vllm.py)
# vLLM has many dependencies and may reinstall torch - think if this is normal in your case
# vllm>=0.6.0
